{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f693a1f-77d5-4dca-b5dc-b55880fd42b6",
   "metadata": {},
   "source": [
    "# Binder Test Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fce4683c-d9eb-43d6-955d-e79e0540c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "import re\n",
    "import yaml\n",
    "import urllib\n",
    "import boto3\n",
    "import glob\n",
    "import requests, json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664fa1e-e84b-411b-963e-65274579bd39",
   "metadata": {},
   "source": [
    "### Configuration for fetching NOAA NOS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6780066f-64ff-400f-afda-c8e6daa277b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id = '8536110'\n",
    "datum = 'MLLW'\n",
    "product = 'water_level'\n",
    "time_zone = 'gmt'\n",
    "units = 'metric'\n",
    "file_format = 'csv'\n",
    "start_dt = '20190101'\n",
    "end_dt = '20191231'\n",
    "path = os.path.dirname('/01_fetch/out/')\n",
    "os.path.isdir(path)\n",
    "filename = f\"noaa_nos_{station_id}_{product}_{start_dt}_{end_dt}.csv\"\n",
    "data_outfile = os.path.join('.', path + '/' + filename)\n",
    "metadata_path = os.path.dirname('/01_fetch/out/metadata/')\n",
    "metadata_filename = f\"noaa_nos_metadata_{station_id}.csv\"\n",
    "metadata_outfile = os.path.join('.', metadata_path + '/' + metadata_filename)\n",
    "Bucket = 'drb-estuary-salinity'\n",
    "session = boto3.Session(profile_name='dev')\n",
    "s3_client = session.client('s3')\n",
    "write_location = 'S3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b8cf2-557e-4926-ba8b-e734e684d14c",
   "metadata": {},
   "source": [
    "Fetch Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1cb8acb-6c11-4149-a247-2526c9e3be66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading to s3\n"
     ]
    }
   ],
   "source": [
    "'''fetch NOAA NOS data from select station. Change product argument for NOAA NOS data product.\n",
    "(ie. product = current for current data)'''\n",
    "data_url = f'https://api.tidesandcurrents.noaa.gov/api/prod/datagetter?product=predictions&application=NOS.COOPS.TAC.WL&begin_date=' \\\n",
    "            f'{start_dt}&end_date={end_dt}&datum={datum}&station={station_id}&product={product}&time_zone=' \\\n",
    "            f'{time_zone}&units={units}&interval=&format={file_format}'\n",
    "urllib.request.urlretrieve(data_url, data_outfile)\n",
    "if write_location == 'S3':\n",
    "    print('uploading to s3')\n",
    "    s3_client.upload_file(data_outfile, bucket, '01_fetch/out/'+os.path.basename(data_outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a809626-09ff-4b59-be91-8d84ef8a6d73",
   "metadata": {},
   "source": [
    "Fetch metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4725021f-ed55-46c7-8d89-9fd9ef40b843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading to s3\n"
     ]
    }
   ],
   "source": [
    "'''fetch tides and currents metadata from NOAA NOS station'''\n",
    "metadata_url = f'https://api.tidesandcurrents.noaa.gov/mdapi/prod/webapi/stations/{station_id}/.json'\n",
    "response = requests.get(metadata_url)\n",
    "text = response.text\n",
    "data = json.loads(text)\n",
    "nested_list = pd.json_normalize(data, record_path=['stations'])\n",
    "df = nested_list.stack().reset_index()\n",
    "metadata = df.iloc[1:, 1:].rename(columns={df.columns[1]: \"data_property\",\n",
    "                                            df.columns[2]: (station_id)}).replace(\".self\", \"\", regex=True)\n",
    "metadata.to_csv(metadata_outfile, index=False)\n",
    "if write_location == 'S3':\n",
    "    print('uploading to s3')\n",
    "    s3_client.upload_file(metadata_outfile, bucket, '01_fetch/out/'+os.path.basename(metadata_outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f2194b-420c-461d-9282-f21825e2d243",
   "metadata": {},
   "source": [
    "combine csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa33c2-7216-48dd-8b5f-e22f59079e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = 'S3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe9945-fd4d-42ed-891f-58e5f908d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to files\n",
    "file_dir = os.path.join(f\"{file_location}\", f\"noaa_nos_metadata_*.csv\")\n",
    "# A list of all csv\n",
    "file_list = glob.glob(file_dir)\n",
    "# join csvs\n",
    "df = pd.concat(map(pd.read_csv, file_list), ignore_index=True, sort = True)\n",
    "if save_location = 'S3\"\n",
    "    #define key to point to datasets for specified station\n",
    "    key = f'01_fetch/out/noaa_nos_{station_id}'\n",
    "    #create a list of csv files in s3 bucket with observational data specific to station\n",
    "    prefix_df = []\n",
    "    prefix_obs = [obj['Key'] for obj in s3_client.list_objects_v2(Bucket=s3_bucket, Prefix=f'01_fetch/out/noaa_nos_{station_id}')['Contents']]\n",
    "    #grab each dataset from bucket and combine to a single csv file\n",
    "        for obs in prefix_obs:\n",
    "            obj = s3_client.get_object(Bucket=s3_bucket, Key=obs)\n",
    "            temp = pd.read_csv(obj.get('Body'), index_col=None, header=0, encoding='utf8')\n",
    "            prefix_df.append(temp)\n",
    "    #sort columns to timestep\n",
    "    df = pd.concat(prefix_df, ignore_index=True, sort = True)\n",
    "    #save to csv file\n",
    "    if write_location == 'S3':\n",
    "           print('uploading to s3')\n",
    "           s3_client.upload_file(data_outfile_csv, s3_bucket, '02_munge/out/'+os.path.basename(data_outfile_csv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
